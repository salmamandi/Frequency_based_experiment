{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import csv\n",
    "\n",
    "from statistics import mean\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from numpy import linalg as LA\n",
    "import sklearn\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_files/U1_LIHF_itd_file.csv\n",
      "number of unique ID=114\n",
      "Total number of samples/buckets=114\n",
      "length of maximum list=2539\n",
      "Data_files/U2_LIHF_itd_file.csv\n",
      "number of unique ID=45\n",
      "Total number of samples/buckets=45\n",
      "length of maximum list=2539\n",
      "Data_files/U3_LIHF_itd_file.csv\n",
      "number of unique ID=48\n",
      "Total number of samples/buckets=45\n",
      "length of maximum list=339\n",
      "Data_files/U4_LIHF_itd_file.csv\n",
      "number of unique ID=118\n",
      "Total number of samples/buckets=118\n",
      "length of maximum list=1975\n",
      "Data_files/U5_LIHF_itd_file.csv\n",
      "number of unique ID=66\n",
      "Total number of samples/buckets=66\n",
      "length of maximum list=2539\n",
      "Data_files/U6_LIHF_itd_file.csv\n",
      "number of unique ID=49\n",
      "Total number of samples/buckets=49\n",
      "length of maximum list=162\n",
      "Data_files/U7_LIHF_itd_file.csv\n",
      "number of unique ID=111\n",
      "Total number of samples/buckets=111\n",
      "length of maximum list=227\n",
      "Data_files/U8_LIHF_itd_file.csv\n",
      "number of unique ID=27\n",
      "Total number of samples/buckets=27\n",
      "length of maximum list=433\n",
      "Data_files/U9_LIHF_itd_file.csv\n",
      "number of unique ID=49\n",
      "Total number of samples/buckets=45\n",
      "length of maximum list=552\n",
      "Data_files/U10_LIHF_itd_file.csv\n",
      "number of unique ID=89\n",
      "Total number of samples/buckets=89\n",
      "length of maximum list=2316\n",
      "Data_files/U11_LIHF_itd_file.csv\n",
      "number of unique ID=54\n",
      "Total number of samples/buckets=54\n",
      "length of maximum list=1021\n",
      "Data_files/U12_LIHF_itd_file.csv\n",
      "number of unique ID=340\n",
      "Total number of samples/buckets=340\n",
      "length of maximum list=4193\n",
      "Data_files/U13_LIHF_itd_file.csv\n",
      "number of unique ID=68\n",
      "Total number of samples/buckets=67\n",
      "length of maximum list=1149\n",
      "Data_files/U14_LIHF_itd_file.csv\n",
      "number of unique ID=46\n",
      "Total number of samples/buckets=46\n",
      "length of maximum list=1873\n",
      "Data_files/U15_LIHF_itd_file.csv\n",
      "number of unique ID=148\n",
      "Total number of samples/buckets=148\n",
      "length of maximum list=2344\n",
      "Data_files/U16_LIHF_itd_file.csv\n",
      "number of unique ID=237\n",
      "Total number of samples/buckets=237\n",
      "length of maximum list=3274\n",
      "Data_files/U17_LIHF_itd_file.csv\n",
      "number of unique ID=89\n",
      "Total number of samples/buckets=89\n",
      "length of maximum list=2407\n",
      "Data_files/U18_LIHF_itd_file.csv\n",
      "number of unique ID=38\n",
      "Total number of samples/buckets=38\n",
      "length of maximum list=677\n",
      "Data_files/U19_LIHF_itd_file.csv\n",
      "number of unique ID=119\n",
      "Total number of samples/buckets=112\n",
      "length of maximum list=3512\n",
      "Data_files/U20_LIHF_itd_file.csv\n",
      "number of unique ID=182\n",
      "Total number of samples/buckets=182\n",
      "length of maximum list=758\n",
      "Data_files/U21_LIHF_itd_file.csv\n",
      "number of unique ID=115\n",
      "Total number of samples/buckets=109\n",
      "length of maximum list=6543\n",
      "Data_files/U22_LIHF_itd_file.csv\n",
      "number of unique ID=46\n",
      "Total number of samples/buckets=46\n",
      "length of maximum list=1219\n"
     ]
    }
   ],
   "source": [
    "def pad(l, content, width):\n",
    "    l.extend([content] * (width - len(l)))\n",
    "    return l\n",
    "\n",
    "def trunct(l,width):\n",
    "    for i in range(0,len(l)-width):\n",
    "        l.pop()\n",
    "    return l    \n",
    "\n",
    "# Retrieving samples for each emotion\n",
    "usr_dir=\"Data_files/\"\n",
    "for user in range(1,23,1):\n",
    "    usr_file=usr_dir+\"U\"+str(user)+\"_LIHF_itd_file.csv\"\n",
    "    \n",
    "    \n",
    "    happy_bucket=[]\n",
    "    sad_bucket=[]\n",
    "    stressed_bucket=[]\n",
    "    relax_bucket=[]\n",
    "    \n",
    "    print(usr_file)\n",
    "    dataset=pd.read_csv(usr_file,header=None)\n",
    "    dataframe=dataset.values\n",
    "    \n",
    "    #print(\"row_number=\"+str(dataframe.shape[0]))\n",
    "    \n",
    "    # value list holds unique id \n",
    "    value_list=[]\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        value_list.append(dataframe[i][0])\n",
    "        \n",
    "    ID_list=list(set(value_list))\n",
    "    ID_list.sort()\n",
    "    print(\"number of unique ID=\"+str(len(ID_list)))\n",
    "    start=0\n",
    "    next_start=0\n",
    "    # traverse the whole list and add list of ITD values in emotion list\n",
    "    for i in range(len(ID_list)):\n",
    "        ID_number=ID_list[i]\n",
    "        #print(\"ID_number=\"+str(ID_number))\n",
    "        ITD_values=[]\n",
    "        \n",
    "        for j in range(start,dataframe.shape[0],1):\n",
    "            if(dataframe[j][0]==ID_number):\n",
    "                ITD_values.append(dataframe[j][2])\n",
    "                next_start=next_start+1\n",
    "            else:\n",
    "                start=next_start\n",
    "                #print(next_start)\n",
    "                break\n",
    "        if(dataframe[j-1][4]==2 and len(ITD_values)>3):\n",
    "             happy_bucket.append(list(ITD_values))\n",
    "        if(dataframe[j-1][4]==-2 and len(ITD_values)>3):\n",
    "             sad_bucket.append(list(ITD_values))\n",
    "        if(dataframe[j-1][4]==1 and len(ITD_values)>3):\n",
    "             stressed_bucket.append(list(ITD_values))\n",
    "        if(dataframe[j-1][4]==0 and len(ITD_values)>3):\n",
    "            relax_bucket.append(list(ITD_values))\n",
    "        #print(\"ID_number=\"+str(ID_number)+\",\"+\"length of list=\"+str(len(ITD_values)))\n",
    "    print(\"Total number of samples/buckets=\"+str(len(happy_bucket)+len(sad_bucket)+len(stressed_bucket)+len(relax_bucket)))\n",
    "    count_ITD_list=len(happy_bucket)+len(sad_bucket)+len(stressed_bucket)+len(relax_bucket)\n",
    "    \n",
    "    # extending all samples to the length of sample with maximum length\n",
    "    \n",
    "    length_lists=[]\n",
    "    \n",
    "    for itd_list in happy_bucket:\n",
    "        length_lists.append(len(itd_list))\n",
    "    #print(length_lists)  \n",
    "    for itd_list in sad_bucket:\n",
    "        length_lists.append(len(itd_list))\n",
    "    for itd_list in stressed_bucket:\n",
    "        length_lists.append(len(itd_list))  \n",
    "    for itd_list in relax_bucket:\n",
    "        length_lists.append(len(itd_list))  \n",
    "    \n",
    "    # this is to make a list to the length of list with maximum length/average length\n",
    "    print(\"length of maximum list=\"+str(max(length_lists)))\n",
    "    #max_length=max(length_lists) \n",
    "    avg_length=round(mean(length_lists))\n",
    "    \n",
    "    for i in range(len(happy_bucket)):\n",
    "        if(len(happy_bucket[i])>avg_length):\n",
    "            happy_bucket[i]=trunct(happy_bucket[i],avg_length)\n",
    "        elif(len(happy_bucket[i])<avg_length):    \n",
    "            happy_bucket[i]=pad(happy_bucket[i],0,avg_length)\n",
    "            \n",
    "        #happy_bucket[i]=pad(happy_bucket[i],0,max_length)\n",
    "        # append label\n",
    "        happy_bucket[i].append(2)\n",
    "        \n",
    "    for i in range(len(sad_bucket)):\n",
    "        if(len(sad_bucket[i])>avg_length):\n",
    "            sad_bucket[i]=trunct(sad_bucket[i],avg_length)\n",
    "        elif(len(sad_bucket[i])<avg_length):    \n",
    "            sad_bucket[i]=pad(sad_bucket[i],0,avg_length)\n",
    "        #sad_bucket[i]=pad(sad_bucket[i],0,max_length)\n",
    "        # append label\n",
    "        sad_bucket[i].append(-2)\n",
    "    \n",
    "    for i in range(len(stressed_bucket)):\n",
    "        if(len(stressed_bucket[i])>avg_length):\n",
    "            stressed_bucket[i]=trunct(stressed_bucket[i],avg_length)\n",
    "        elif(len(stressed_bucket[i])<avg_length):    \n",
    "            stressed_bucket[i]=pad(stressed_bucket[i],0,avg_length)\n",
    "        #stressed_bucket[i]=pad(stressed_bucket[i],0,max_length)\n",
    "        # append label\n",
    "        stressed_bucket[i].append(1)\n",
    "        \n",
    "    for i in range(len(relax_bucket)):\n",
    "        if(len(relax_bucket[i])>avg_length):\n",
    "            relax_bucket[i]=trunct(relax_bucket[i],avg_length)\n",
    "        elif(len(relax_bucket[i])<avg_length):    \n",
    "            relax_bucket[i]=pad(relax_bucket[i],0,avg_length)\n",
    "        #relax_bucket[i]=pad(relax_bucket[i],0,max_length)\n",
    "        # append label\n",
    "        relax_bucket[i].append(0)  \n",
    "        \n",
    "    ######### writting itd_list in a file for further processing #################################    \n",
    "    raw_file=\"Raw_data/ITD_list_avg/\"+\"U\"+str(user)+\"_LIHF_itd_file.csv\"  \n",
    "    with open(raw_file,\"w\") as resultfile:\n",
    "        writer=csv.writer(resultfile)\n",
    "        writer.writerows(happy_bucket)\n",
    "        writer.writerows(sad_bucket)\n",
    "        writer.writerows(stressed_bucket)\n",
    "        writer.writerows(relax_bucket)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
