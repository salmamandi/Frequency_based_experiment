{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import csv\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from numpy import linalg as LA\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from scipy.signal import find_peaks\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_files/U1_LIHF_itd_file.csv\n",
      "number of unique ID=114\n",
      "sum of bucket length=114\n",
      "Happy list length= 31 sad list length= 23\n",
      "happy char list length= 31 sad char list length= 23\n",
      "Stressed list length= 9 relaxed list length= 51\n",
      "stressed char list length= 9 Relaxed char list length= 51\n",
      "length of data= 114\n",
      "Data_files/U2_LIHF_itd_file.csv\n",
      "number of unique ID=45\n",
      "sum of bucket length=45\n",
      "Happy list length= 13 sad list length= 8\n",
      "happy char list length= 13 sad char list length= 8\n",
      "Stressed list length= 4 relaxed list length= 20\n",
      "stressed char list length= 4 Relaxed char list length= 20\n",
      "length of data= 45\n",
      "Data_files/U3_LIHF_itd_file.csv\n",
      "number of unique ID=48\n",
      "sum of bucket length=45\n",
      "Happy list length= 5 sad list length= 7\n",
      "happy char list length= 5 sad char list length= 7\n",
      "Stressed list length= 2 relaxed list length= 31\n",
      "stressed char list length= 2 Relaxed char list length= 31\n",
      "length of data= 45\n",
      "Data_files/U4_LIHF_itd_file.csv\n",
      "number of unique ID=118\n",
      "sum of bucket length=118\n",
      "Happy list length= 5 sad list length= 15\n",
      "happy char list length= 5 sad char list length= 15\n",
      "Stressed list length= 31 relaxed list length= 67\n",
      "stressed char list length= 31 Relaxed char list length= 67\n",
      "length of data= 118\n",
      "Data_files/U5_LIHF_itd_file.csv\n",
      "number of unique ID=66\n",
      "sum of bucket length=66\n",
      "Happy list length= 20 sad list length= 9\n",
      "happy char list length= 20 sad char list length= 9\n",
      "Stressed list length= 4 relaxed list length= 33\n",
      "stressed char list length= 4 Relaxed char list length= 33\n",
      "length of data= 66\n",
      "Data_files/U6_LIHF_itd_file.csv\n",
      "number of unique ID=49\n",
      "sum of bucket length=49\n",
      "Happy list length= 12 sad list length= 6\n",
      "happy char list length= 12 sad char list length= 6\n",
      "Stressed list length= 2 relaxed list length= 29\n",
      "stressed char list length= 2 Relaxed char list length= 29\n",
      "length of data= 49\n",
      "Data_files/U7_LIHF_itd_file.csv\n",
      "number of unique ID=111\n",
      "sum of bucket length=111\n",
      "Happy list length= 37 sad list length= 13\n",
      "happy char list length= 37 sad char list length= 13\n",
      "Stressed list length= 9 relaxed list length= 52\n",
      "stressed char list length= 9 Relaxed char list length= 52\n",
      "length of data= 111\n",
      "Data_files/U8_LIHF_itd_file.csv\n",
      "number of unique ID=27\n",
      "sum of bucket length=27\n",
      "Happy list length= 13 sad list length= 1\n",
      "happy char list length= 13 sad char list length= 1\n",
      "Stressed list length= 2 relaxed list length= 11\n",
      "stressed char list length= 2 Relaxed char list length= 11\n",
      "length of data= 27\n",
      "Data_files/U9_LIHF_itd_file.csv\n",
      "number of unique ID=49\n",
      "sum of bucket length=45\n",
      "Happy list length= 5 sad list length= 11\n",
      "happy char list length= 5 sad char list length= 11\n",
      "Stressed list length= 4 relaxed list length= 25\n",
      "stressed char list length= 4 Relaxed char list length= 25\n",
      "length of data= 45\n",
      "Data_files/U10_LIHF_itd_file.csv\n",
      "number of unique ID=89\n",
      "sum of bucket length=89\n",
      "Happy list length= 4 sad list length= 20\n",
      "happy char list length= 4 sad char list length= 20\n",
      "Stressed list length= 1 relaxed list length= 64\n",
      "stressed char list length= 1 Relaxed char list length= 64\n",
      "length of data= 89\n",
      "Data_files/U11_LIHF_itd_file.csv\n",
      "number of unique ID=54\n",
      "sum of bucket length=54\n",
      "Happy list length= 0 sad list length= 19\n",
      "happy char list length= 0 sad char list length= 19\n",
      "Stressed list length= 13 relaxed list length= 22\n",
      "stressed char list length= 13 Relaxed char list length= 22\n",
      "length of data= 54\n",
      "Data_files/U12_LIHF_itd_file.csv\n",
      "number of unique ID=340\n",
      "sum of bucket length=340\n",
      "Happy list length= 10 sad list length= 0\n",
      "happy char list length= 10 sad char list length= 0\n",
      "Stressed list length= 32 relaxed list length= 298\n",
      "stressed char list length= 32 Relaxed char list length= 298\n",
      "length of data= 340\n",
      "Data_files/U13_LIHF_itd_file.csv\n",
      "number of unique ID=68\n",
      "sum of bucket length=67\n",
      "Happy list length= 14 sad list length= 3\n",
      "happy char list length= 14 sad char list length= 3\n",
      "Stressed list length= 26 relaxed list length= 24\n",
      "stressed char list length= 26 Relaxed char list length= 24\n",
      "length of data= 67\n",
      "Data_files/U14_LIHF_itd_file.csv\n",
      "number of unique ID=46\n",
      "sum of bucket length=46\n",
      "Happy list length= 2 sad list length= 6\n",
      "happy char list length= 2 sad char list length= 6\n",
      "Stressed list length= 7 relaxed list length= 31\n",
      "stressed char list length= 7 Relaxed char list length= 31\n",
      "length of data= 46\n",
      "Data_files/U15_LIHF_itd_file.csv\n",
      "number of unique ID=148\n",
      "sum of bucket length=148\n",
      "Happy list length= 12 sad list length= 21\n",
      "happy char list length= 12 sad char list length= 21\n",
      "Stressed list length= 0 relaxed list length= 115\n",
      "stressed char list length= 0 Relaxed char list length= 115\n",
      "length of data= 148\n",
      "Data_files/U16_LIHF_itd_file.csv\n",
      "number of unique ID=237\n",
      "sum of bucket length=237\n",
      "Happy list length= 1 sad list length= 9\n",
      "happy char list length= 1 sad char list length= 9\n",
      "Stressed list length= 189 relaxed list length= 38\n",
      "stressed char list length= 189 Relaxed char list length= 38\n",
      "length of data= 237\n",
      "Data_files/U17_LIHF_itd_file.csv\n",
      "number of unique ID=89\n",
      "sum of bucket length=89\n",
      "Happy list length= 0 sad list length= 2\n",
      "happy char list length= 0 sad char list length= 2\n",
      "Stressed list length= 41 relaxed list length= 46\n",
      "stressed char list length= 41 Relaxed char list length= 46\n",
      "length of data= 89\n",
      "Data_files/U18_LIHF_itd_file.csv\n",
      "number of unique ID=38\n",
      "sum of bucket length=38\n",
      "Happy list length= 26 sad list length= 0\n",
      "happy char list length= 26 sad char list length= 0\n",
      "Stressed list length= 3 relaxed list length= 9\n",
      "stressed char list length= 3 Relaxed char list length= 9\n",
      "length of data= 38\n",
      "Data_files/U19_LIHF_itd_file.csv\n",
      "number of unique ID=119\n",
      "sum of bucket length=112\n",
      "Happy list length= 54 sad list length= 10\n",
      "happy char list length= 54 sad char list length= 10\n",
      "Stressed list length= 7 relaxed list length= 41\n",
      "stressed char list length= 7 Relaxed char list length= 41\n",
      "length of data= 112\n",
      "Data_files/U20_LIHF_itd_file.csv\n",
      "number of unique ID=182\n",
      "sum of bucket length=182\n",
      "Happy list length= 85 sad list length= 23\n",
      "happy char list length= 85 sad char list length= 23\n",
      "Stressed list length= 55 relaxed list length= 19\n",
      "stressed char list length= 55 Relaxed char list length= 19\n",
      "length of data= 182\n",
      "Data_files/U21_LIHF_itd_file.csv\n",
      "number of unique ID=115\n",
      "sum of bucket length=109\n",
      "Happy list length= 36 sad list length= 5\n",
      "happy char list length= 36 sad char list length= 5\n",
      "Stressed list length= 9 relaxed list length= 59\n",
      "stressed char list length= 9 Relaxed char list length= 59\n",
      "length of data= 109\n",
      "Data_files/U22_LIHF_itd_file.csv\n",
      "number of unique ID=46\n",
      "sum of bucket length=46\n",
      "Happy list length= 15 sad list length= 0\n",
      "happy char list length= 15 sad char list length= 0\n",
      "Stressed list length= 6 relaxed list length= 25\n",
      "stressed char list length= 6 Relaxed char list length= 25\n",
      "length of data= 46\n"
     ]
    }
   ],
   "source": [
    "def pad(l, content, width):\n",
    "    l.extend([content] * (width - len(l)))\n",
    "    return l\n",
    "\n",
    "def ITD_mean_cal(l):\n",
    "    x=mean(l)\n",
    "    return x\n",
    "\n",
    "def Refined_mean(l):\n",
    "    ITD_collect=[]\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(l)\n",
    "    X=kmeans.labels_\n",
    "    #print(X)\n",
    "    one_count = np.count_nonzero(X == 1)\n",
    "    zero_count=np.count_nonzero(X == 0)\n",
    "    #print(\"one_count=\",one_count,\",zero_count=\",zero_count)\n",
    "    if(one_count>=zero_count):\n",
    "        index_list= np.where(X == 1)\n",
    "        count=one_count\n",
    "    else:\n",
    "        index_list= np.where(X == 0)\n",
    "        count=zero_count\n",
    "    for i in range(count):\n",
    "        #print(type(index_list[0][i].astype(np.int)))\\\n",
    "        ITD_collect.append(l[np.int16(index_list[0][i]).item()])\n",
    "    #print(ITD_collect)\n",
    "    ITD_collect=np.array(ITD_collect)\n",
    "    mean=np.mean(ITD_collect)\n",
    "    return mean\n",
    "    \n",
    "def Special_char_count(l): \n",
    "    no_splchar=0\n",
    "    for keyAscii in l:\n",
    "        if(not(keyAscii>=48 and keyAscii <= 57) and not(keyAscii >= 65 and keyAscii <= 90) and not(keyAscii >= 97 and keyAscii <= 122) and keyAscii!=-5):\n",
    "            \n",
    "            no_splchar+=1\n",
    "            \n",
    "    return no_splchar \n",
    "\n",
    "def backspce_count(l):\n",
    "    no_backspce=0\n",
    "    for keyAscii in l:\n",
    "        if(keyAscii== -5):\n",
    "            no_backspce+=1\n",
    "    return no_backspce\n",
    "\n",
    "usr_dir=\"Data_files/\"\n",
    "for user in range(1,23,1):\n",
    "    usr_file=usr_dir+\"U\"+str(user)+\"_LIHF_itd_file.csv\"\n",
    "    \n",
    "    data=[]\n",
    "    happy_bucket=[]\n",
    "    sad_bucket=[]\n",
    "    stressed_bucket=[]\n",
    "    relax_bucket=[]\n",
    "    #################\n",
    "    happy_char=[]\n",
    "    sad_char=[]\n",
    "    stressed_char=[]\n",
    "    relax_char=[]\n",
    "    \n",
    "    print(usr_file)\n",
    "    dataset=pd.read_csv(usr_file,header=None)\n",
    "    dataframe=dataset.values\n",
    "    \n",
    "    #print(\"row_number=\"+str(dataframe.shape[0]))\n",
    "    \n",
    "    # value list holds unique id \n",
    "    value_list=[]\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        value_list.append(dataframe[i][0])\n",
    "        \n",
    "    ID_list=list(set(value_list))\n",
    "    ID_list.sort()\n",
    "    print(\"number of unique ID=\"+str(len(ID_list)))\n",
    "    start=0\n",
    "    next_start=0\n",
    "    # traverse the whole list and add list of ITD values in emotion list\n",
    "    for i in range(len(ID_list)):\n",
    "        ID_number=ID_list[i]\n",
    "        #print(\"ID_number=\"+str(ID_number))\n",
    "        ITD_values=[]\n",
    "        #### for time domain feature took character list #####\n",
    "        char_list=[]\n",
    "        for j in range(start,dataframe.shape[0],1):\n",
    "            if(dataframe[j][0]==ID_number):\n",
    "                ITD_values.append(dataframe[j][2])\n",
    "                char_list.append(dataframe[j][3])\n",
    "                next_start=next_start+1\n",
    "            else:\n",
    "                start=next_start\n",
    "                #print(next_start)\n",
    "                break\n",
    "        if(dataframe[j-1][4]==2 and len(ITD_values)>3):\n",
    "            happy_bucket.append(list(ITD_values))\n",
    "            time_char_feature=[Special_char_count(char_list),backspce_count(char_list),len(char_list)]\n",
    "            happy_char.append(list(time_char_feature))\n",
    "            \n",
    "            \n",
    "        if(dataframe[j-1][4]==-2 and len(ITD_values)>3):\n",
    "            sad_bucket.append(list(ITD_values))\n",
    "            time_char_feature=[Special_char_count(char_list),backspce_count(char_list),len(char_list)]\n",
    "            sad_char.append(list(time_char_feature))  \n",
    "            \n",
    "        if(dataframe[j-1][4]==1 and len(ITD_values)>3):\n",
    "            stressed_bucket.append(list(ITD_values))\n",
    "            time_char_feature=[Special_char_count(char_list),backspce_count(char_list),len(char_list)]\n",
    "            stressed_char.append(list(time_char_feature)) \n",
    "            \n",
    "        if(dataframe[j-1][4]==0 and len(ITD_values)>3):\n",
    "            relax_bucket.append(list(ITD_values))\n",
    "            time_char_feature=[Special_char_count(char_list),backspce_count(char_list),len(char_list)]\n",
    "            relax_char.append(list(time_char_feature))\n",
    "        #print(\"ID_number=\"+str(ID_number)+\",\"+\"length of list=\"+str(len(ITD_values)))\n",
    "    print(\"sum of bucket length=\"+str(len(happy_bucket)+len(sad_bucket)+len(stressed_bucket)+len(relax_bucket)))\n",
    "    count_ITD_list=len(happy_bucket)+len(sad_bucket)+len(stressed_bucket)+len(relax_bucket)\n",
    "    \n",
    "    print(\"Happy list length=\",len(happy_bucket),\"sad list length=\",len(sad_bucket))\n",
    "    print(\"happy char list length=\",len(happy_char),\"sad char list length=\",len(sad_char))\n",
    "    print(\"Stressed list length=\",len(stressed_bucket),\"relaxed list length=\",len(relax_bucket))\n",
    "    \n",
    "    print(\"stressed char list length=\",len(stressed_char),\"Relaxed char list length=\",len(relax_char))\n",
    "    \n",
    "    ############### raw data reading #############################\n",
    "    \n",
    "    #target_file=\"encoded_input/Amp/\"+\"U\"+str(user)+\"_LIHF_itd_file.csv\"\n",
    "    #target_data=pd.read_csv(target_file,header=None)\n",
    "    #target_array=target_data.values\n",
    "    \n",
    "    #col_count=target_array.shape[1]\n",
    "    #raw_data=target_array[:,0:col_count-1]\n",
    "    #print(\"raw data size=\",raw_data.shape[0])\n",
    "    #######################################################\n",
    "    #happy_index=0\n",
    "    for (itd_list,char_list) in zip(happy_bucket,happy_char):\n",
    "        # time feature calculation\n",
    "        l=np.array(itd_list)\n",
    "        l=np.reshape(l,(len(l),1))\n",
    "        time_list=[ITD_mean_cal(itd_list),Refined_mean(l)]\n",
    "        ###########################\n",
    "        peak_list=[]\n",
    "        freq_list=[]\n",
    "        gap_list=[]\n",
    "        signal=np.array(itd_list,dtype=float)\n",
    "        # taking absolute value after fft\n",
    "        sp=np.abs(np.fft.fft(signal))\n",
    "        # frequency from fft\n",
    "        freq=np.fft.fftfreq(sp.size)\n",
    "        # indicies for peaks\n",
    "        peaks,_=find_peaks(sp)\n",
    "        for i in range(len(peaks)):\n",
    "            peak_list.append(sp[peaks[i]])\n",
    "            freq_list.append(freq[peaks[i]])\n",
    "            \n",
    "        peak_list=np.array(peak_list)\n",
    "        freq_list=np.array(freq_list)\n",
    "        #ind = np.argpartition(peak_list, -3)[-3:]\n",
    "        #print(peak_list)\n",
    "        \n",
    "        # find indices of top most amplitude in sorted order\n",
    "        ind=peak_list.argsort()[-3:][::-1]\n",
    "        #print(peak_list[ind])\n",
    "        #print(freq_list[ind])\n",
    "        # concatenate peak amplitude and frequency\n",
    "        #print(peak_list[ind])\n",
    "        for val in ind:\n",
    "            gap_list.append(peaks[val])\n",
    "        gap_list.sort()\n",
    "        \n",
    "        #print(gap_list)\n",
    "        \n",
    "        for k in range(len(gap_list)-1):\n",
    "            gap_list[k]=gap_list[k+1]-gap_list[k]\n",
    "        if(len(gap_list)!=0):\n",
    "            gap_list.remove(gap_list[-1])\n",
    "        #gap_list.append(2)\n",
    "        #print(freq[ind])\n",
    "        row=np.concatenate((peak_list[ind],freq_list[ind]))\n",
    "        # whole data is collected in data\n",
    "        temp=np.append(row,gap_list).tolist()\n",
    "        if(len(temp)<8):\n",
    "            temp=pad(temp,0,8)\n",
    "        temp.append(2)  \n",
    "        temp=time_list+char_list+temp\n",
    "        data.append(temp)\n",
    "        \n",
    "    \n",
    "    sad_index=0    \n",
    "    for (itd_list,char_list) in zip(sad_bucket,sad_char):\n",
    "        l=np.array(itd_list)\n",
    "        l=np.reshape(l,(len(l),1))\n",
    "        time_list=[ITD_mean_cal(itd_list),Refined_mean(l)]\n",
    "        \n",
    "        peak_list=[]\n",
    "        freq_list=[]\n",
    "        gap_list=[]\n",
    "        signal=np.array(itd_list,dtype=float)\n",
    "        sp=np.abs(np.fft.fft(signal))\n",
    "        freq=np.fft.fftfreq(sp.size)\n",
    "        peaks,_=find_peaks(sp)\n",
    "        for i in range(len(peaks)):\n",
    "            peak_list.append(sp[peaks[i]])\n",
    "            freq_list.append(freq[peaks[i]])\n",
    "        peak_list=np.array(peak_list)\n",
    "        freq_list=np.array(freq_list)\n",
    "        #ind = np.argpartition(peak_list, -3)[-3:]\n",
    "        #print(peak_list)\n",
    "        ind=peak_list.argsort()[-3:][::-1]\n",
    "        \n",
    "        for val in ind:\n",
    "            gap_list.append(peaks[val])\n",
    "        gap_list.sort()  \n",
    "        #print(gap_list)\n",
    "        for k in range(len(gap_list)-1):\n",
    "            gap_list[k]=gap_list[k+1]-gap_list[k]\n",
    "        if(len(gap_list)!=0):\n",
    "            gap_list.remove(gap_list[-1])\n",
    "        #gap_list.append(-2)\n",
    "        #print(peak_list[ind])\n",
    "        #print(freq[ind])\n",
    "        \n",
    "        row=np.concatenate((peak_list[ind],freq_list[ind]))\n",
    "        # whole data is collected in data\n",
    "        temp=np.append(row,gap_list).tolist()\n",
    "        if(len(temp)<8):\n",
    "            temp=pad(temp,0,8)\n",
    "        temp.append(-2)\n",
    "        temp=time_list+char_list+temp\n",
    "        data.append(temp)\n",
    "        \n",
    "     \n",
    " \n",
    "    for (itd_list,char_list) in zip(stressed_bucket,stressed_char):\n",
    "        l=np.array(itd_list)\n",
    "        l=np.reshape(l,(len(l),1))\n",
    "        time_list=[ITD_mean_cal(itd_list),Refined_mean(l)]\n",
    "        \n",
    "        peak_list=[]\n",
    "        freq_list=[]\n",
    "        gap_list=[]\n",
    "        signal=np.array(itd_list,dtype=float)\n",
    "        sp=np.abs(np.fft.fft(signal))\n",
    "        freq=np.fft.fftfreq(sp.size)\n",
    "        peaks,_=find_peaks(sp)\n",
    "        for i in range(len(peaks)):\n",
    "            peak_list.append(sp[peaks[i]])\n",
    "            freq_list.append(freq[peaks[i]])\n",
    "        peak_list=np.array(peak_list)\n",
    "        freq_list=np.array(freq_list)\n",
    "        #ind = np.argpartition(peak_list, -3)[-3:]\n",
    "        #print(peak_list)\n",
    "        ind=peak_list.argsort()[-3:][::-1]\n",
    "        for val in ind:\n",
    "            gap_list.append(peaks[val])\n",
    "        gap_list.sort()  \n",
    "        #print(gap_list)\n",
    "        for k in range(len(gap_list)-1):\n",
    "            gap_list[k]=gap_list[k+1]-gap_list[k]\n",
    "        if(len(gap_list)!=0):\n",
    "            \n",
    "            gap_list.remove(gap_list[-1])\n",
    "        #gap_list.append(1)\n",
    "        #print(peak_list[ind])\n",
    "        #print(freq[ind])\n",
    "        row=np.concatenate((peak_list[ind],freq_list[ind]))\n",
    "        # whole data is collected in data\n",
    "        temp=np.append(row,gap_list).tolist()\n",
    "        if(len(temp)<8):\n",
    "            temp=pad(temp,0,8)\n",
    "        temp.append(1)   \n",
    "        temp=time_list+char_list+temp\n",
    "        data.append(temp)\n",
    "        \n",
    "    \n",
    "      \n",
    "    for (itd_list,char_list) in zip(relax_bucket,relax_char):\n",
    "        l=np.array(itd_list)\n",
    "        l=np.reshape(l,(len(l),1))\n",
    "        time_list=[ITD_mean_cal(itd_list),Refined_mean(l)]\n",
    "        \n",
    "        peak_list=[]\n",
    "        freq_list=[]\n",
    "        gap_list=[]\n",
    "        signal=np.array(itd_list,dtype=float)\n",
    "        sp=np.abs(np.fft.fft(signal))\n",
    "        freq=np.fft.fftfreq(sp.size)\n",
    "        peaks,_=find_peaks(sp)\n",
    "        for i in range(len(peaks)):\n",
    "            peak_list.append(sp[peaks[i]])\n",
    "            freq_list.append(freq[peaks[i]])\n",
    "        peak_list=np.array(peak_list)\n",
    "        freq_list=np.array(freq_list)\n",
    "        #ind = np.argpartition(peak_list, -3)[-3:]\n",
    "        #print(peak_list)\n",
    "        ind=peak_list.argsort()[-3:][::-1]\n",
    "        for val in ind:\n",
    "            gap_list.append(peaks[val])\n",
    "        gap_list.sort()  \n",
    "        #print(gap_list)\n",
    "        for k in range(len(gap_list)-1):\n",
    "            gap_list[k]=gap_list[k+1]-gap_list[k]\n",
    "        if(len(gap_list)!=0):\n",
    "            \n",
    "            gap_list.remove(gap_list[-1])\n",
    "        #gap_list.append(0)\n",
    "        #print(peak_list[ind])\n",
    "        #print(freq[ind])\n",
    "        row=np.concatenate((peak_list[ind],freq_list[ind]))\n",
    "        # whole data is collected in data\n",
    "        temp=np.append(row,gap_list).tolist()\n",
    "        if(len(temp)<8):\n",
    "            temp=pad(temp,0,8)\n",
    "        temp.append(0) \n",
    "        temp=time_list+char_list+temp\n",
    "        data.append(temp)\n",
    "        \n",
    "        \n",
    "    print(\"length of data=\",len(data))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if(len(data[i])<9):\n",
    "            \n",
    "            print(data[i])\n",
    "            \n",
    "    # this part for writting raw data with feature data        \n",
    "    #raw_data=np.append(raw_data,data,axis=1)\n",
    "    #print(raw_data)\n",
    "    #np.savetxt(\"encoded_input/time_feature_augmented/\"+\"U\"+str(user)+\"_LIHF_itd_file.csv\", raw_data, delimiter=\",\")\n",
    "    \n",
    "    ############################################\n",
    "    writefile=\"encoded_input/FullTime_freq_feature/\"+\"U\"+str(user)+\"_LIHF_itd_file.csv\"\n",
    "    with open(writefile,\"w\") as resultfile:\n",
    "            writer=csv.writer(resultfile)\n",
    "            writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
